{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing using Stanfordnlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing- lematization and remove unnecessary stuff,\n",
    "#from stanfordcorenlp import StanfordCoreNLP\n",
    "\n",
    "import json\n",
    "import re\n",
    "import stanfordnlp\n",
    "from stanfordcorenlp import StanfordCoreNLP\n",
    "\n",
    "def loadData():\n",
    "  with open(\"Sarcasm_Headlines_Dataset.json\",\"r\") as f:\n",
    "    data = [json.loads(line) for line in f]\n",
    "    return data \n",
    "\n",
    "#removes link key value pair\n",
    "def extractData(data):\n",
    "    newData ={}\n",
    "    for i in range(len(data)):\n",
    "        newData[i] = {\"headline\": lemmatize(data[i][\"headline\"]), \"is_sarcastic\": data[i][\"is_sarcastic\"]}\n",
    "    \n",
    "    return newData    \n",
    "  \n",
    "# initialize StanfordCoreNLP\n",
    "nlp = StanfordCoreNLP('http://localhost', port=8000, timeout=30000, lang='en')\n",
    "\n",
    "def lemmatize(text):\n",
    "    # perform lemmatization\n",
    "    lemmas = []\n",
    "    output = nlp.annotate(text, properties={'annotators': 'tokenize,lemma', 'outputFormat': 'json'})\n",
    "    output_dict = json.loads(output)\n",
    "    tokens = output_dict['sentences'][0]['tokens']\n",
    "    for token in tokens:\n",
    "        lemmas.append(token['lemma'])\n",
    "    return lemmas\n",
    "\n",
    "# define preprocessing function\n",
    "def preprocessData():\n",
    "  data = loadData()\n",
    "  newdata = extractData(data)\n",
    "\n",
    "preprocessData()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting Contradiction Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysenti\n",
    "from senticnet.senticnet import SenticNet\n",
    "import string\n",
    "\n",
    "import json\n",
    "import pprint\n",
    "sn = SenticNet()\n",
    "import requests\n",
    "\n",
    "punctuations = set(string.punctuation)\n",
    "word_scores = {}\n",
    "\n",
    "\n",
    "def get_top_concepts(words):\n",
    "    # Concatenate the words to form a comma-separated string\n",
    "    words_str = ','.join(word.lower() for word in words)\n",
    "    \n",
    "    # Make a GET request to the ConceptNet API with the batch of words\n",
    "    url = f'http://api.conceptnet.io/c/en/{words_str}?rel=/r/RelatedTo&limit=10'\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Parse the response JSON and extract the top 5 unique related concepts for each word\n",
    "    concepts = response.json()['edges']\n",
    "    results = {}\n",
    "    for word in words:\n",
    "        seen_concepts = set()\n",
    "        top_concepts = []\n",
    "        for concept in concepts:\n",
    "            end_label = concept['end']['label']\n",
    "            if end_label not in seen_concepts:\n",
    "                top_concepts.append(end_label)\n",
    "                seen_concepts.add(end_label)\n",
    "            if len(top_concepts) == 5:\n",
    "                break\n",
    "        results[word] = top_concepts\n",
    "    \n",
    "    return results\n",
    "\n",
    "def getScoreConceptNet(words):\n",
    "    top_concepts = get_top_concepts(words)\n",
    "    \n",
    "    # Compute the sentiment score for each concept\n",
    "    scores = {}\n",
    "    for word, concepts in top_concepts.items():\n",
    "        word_scores = []\n",
    "        for concept in concepts:\n",
    "            try:\n",
    "                sn_score = sn.polarity_value(concept)\n",
    "                sn_score = 4 * float(sn_score)\n",
    "            except KeyError:\n",
    "                sn_score = None\n",
    "            \n",
    "            if sn_score:\n",
    "                word_scores.append(sn_score)\n",
    "        \n",
    "        # If no sentiment score was found for any of the concepts, set the score as None\n",
    "        if not word_scores:\n",
    "            scores[word] = None\n",
    "        else:\n",
    "            # Compute the average sentiment score\n",
    "            scores[word] = sum(word_scores) / len(word_scores)\n",
    "    \n",
    "    return scores\n",
    "\n",
    "def sentiment(headline):\n",
    "    words = headline.split()\n",
    "    print(words)\n",
    "    sum_pos_score = 0\n",
    "    sum_neg_score = 0\n",
    "    batch_words = []  # List to store the words for batch API call\n",
    "    \n",
    "    for word in words:\n",
    "        if any(char in punctuations for char in word):\n",
    "            continue\n",
    "        \n",
    "        if word in word_scores:  # Check if the word already exists in the dictionary\n",
    "            w_score = word_scores[word]\n",
    "        else:\n",
    "            try:\n",
    "                ss_score = pysenti.get_senti(word)\n",
    "                ss_score = ss_score.scale()\n",
    "            except ValueError:    \n",
    "                ss_score = None\n",
    "            \n",
    "            try:\n",
    "                sn_score = sn.polarity_value(word)\n",
    "                sn_score = 4 * float(sn_score)\n",
    "            except KeyError:\n",
    "                sn_score = None\n",
    "                \n",
    "            if ss_score is not None and sn_score is not None:\n",
    "                w_score = (ss_score + sn_score) / 2\n",
    "            elif ss_score is not None:\n",
    "                w_score = ss_score\n",
    "            elif sn_score is not None:\n",
    "                w_score = sn_score\n",
    "            else:\n",
    "                batch_words.append(word)  # Add the word to the batch words list\n",
    "                w_score = 0\n",
    "            \n",
    "            word_scores[word] = w_score  # Store the calculated score    \n",
    "            \n",
    "        if w_score > 0:\n",
    "           sum_pos_score += w_score\n",
    "        else: \n",
    "            sum_neg_score += w_score\n",
    "\n",
    "    # Batch API call to get scores for words not found in SenticNet and SentiStrength\n",
    "    if batch_words:\n",
    "        batch_scores = getScoreConceptNet(batch_words)\n",
    "        for word, score in batch_scores.items():\n",
    "            w_score = score if score is not None else 0\n",
    "            word_scores[word] = w_score\n",
    "            if w_score > 0:\n",
    "                sum_pos_score += w_score\n",
    "            else:\n",
    "                sum_neg_score += w_score\n",
    "    \n",
    "    print(\"pos:\", sum_pos_score)\n",
    "    print(\"neg:\", sum_neg_score)    \n",
    "    contra = False\n",
    "    if sum_pos_score > 0 and sum_neg_score < 0:\n",
    "        contra = True\n",
    "    return sum_pos_score, sum_neg_score, contra\n",
    "\n",
    "# from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "# sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# def sentiment(headline):\n",
    "#     contra=False\n",
    "#     sum_neg_score=0\n",
    "#     sum_pos_score=0\n",
    "#     sentiment_scores = sia.polarity_scores(headline)\n",
    "#     sum_neg_score=-5*sentiment_scores['neg']        \n",
    "#     sum_pos_score=5*sentiment_scores['pos']\n",
    "    \n",
    "#     if sum_pos_score > 0 and sum_neg_score < 0:\n",
    "#         contra=True\n",
    "#     return sum_pos_score,sum_neg_score,contra  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking Sentence Coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def is_pronoun(token):\n",
    "    return token.pos_ == \"PRON\" or token.pos_ == \"REFLEX\"\n",
    "\n",
    "def check_coreference(s1, s2, w1, w2):\n",
    "    doc1 = nlp(s1)\n",
    "    doc2 = nlp(s2)\n",
    "    \n",
    "    w1_tokens = [token for token in doc1 if token.text == w1]\n",
    "    w2_tokens = [token for token in doc2 if token.text == w2]\n",
    "    \n",
    "    # Rule 1: Pronoun match feature\n",
    "    if w1_tokens and w2_tokens and is_pronoun(w1_tokens[0]) and is_pronoun(w2_tokens[0]):\n",
    "        if w1_tokens[0].text == w2_tokens[0].text:\n",
    "            return True\n",
    "    \n",
    "    # Rule 2: String match feature\n",
    "    if w1.lower() == w2.lower() and w1.lower() not in STOP_WORDS:\n",
    "        return True\n",
    "    \n",
    "    # Rule 3: Definite noun phrase feature\n",
    "    if w2_tokens and w2_tokens[0].text.lower() == \"the\":\n",
    "        return True\n",
    "    \n",
    "    # Rule 4: Demonstrative noun phrase feature\n",
    "    demonstratives = {\"this\", \"that\", \"these\", \"those\", \"here\", \"there\", \"such\", \"so\", \"same\"}\n",
    "    if w2_tokens and w2_tokens[0].text.lower() in demonstratives:\n",
    "        return True\n",
    "\n",
    "    # Rule 5: Both proper names feature\n",
    "    if w1_tokens and w2_tokens and w1_tokens[0].ent_type_ == \"PERSON\" and w2_tokens[0].ent_type_ == \"PERSON\":\n",
    "        return True\n",
    "    \n",
    "    # If none of the rules apply, the sentences are not coherent\n",
    "    return False\n",
    "\n",
    "def check_coherence(headline):\n",
    "    sentences = list(nlp(headline).sents)\n",
    "    s1 = sentences[0].text\n",
    "    doc1 = nlp(s1)\n",
    "    w1 = next((token.text for token in doc1 if token.dep_ == \"nsubj\" or token.dep_ == \"ROOT\"), None)\n",
    "    if w1 is None:\n",
    "        return False\n",
    "    \n",
    "    s2 = sentences[-1].text\n",
    "    doc2 = nlp(s2)\n",
    "    w2 = next((token.text for token in doc2 if token.dep_ == \"dobj\" or token.dep_ == \"pobj\"), None)\n",
    "    if w2 is None:\n",
    "        return False\n",
    "\n",
    "    return check_coreference(s1, s2, w1, w2)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N-Gram Classifier (SVM 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Accuracy: 0.8468738300262074\n",
      "Fold 2 Accuracy: 0.8378884312991389\n",
      "Fold 3 Accuracy: 0.8509921377761138\n",
      "Fold 4 Accuracy: 0.8483713964807188\n",
      "Fold 5 Accuracy: 0.8352676900037439\n",
      "Fold 6 Accuracy: 0.8517409210033695\n",
      "Fold 7 Accuracy: 0.847997004867091\n",
      "Fold 8 Accuracy: 0.8483713964807188\n",
      "Fold 9 Accuracy: 0.842755522276301\n",
      "Fold 10 Accuracy: 0.8550561797752809\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import svm\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import json\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import svm\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "def train_svm1():\n",
    "    # Load the training data from the JSON file\n",
    "    with open(\"Lemma_Data.json\", 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Extract the headlines and labels from the JSON data\n",
    "    headlines = []\n",
    "    labels = []\n",
    "    for i in range(len(data)):\n",
    "        headline = data[str(i)]['headline']\n",
    "        label = data[str(i)]['is_sarcastic']\n",
    "        headlines.append(headline)\n",
    "        labels.append(label)\n",
    "\n",
    "    # Create a CountVectorizer object to extract n-gram features\n",
    "    vectorizer = CountVectorizer(ngram_range=(1, 3))\n",
    "\n",
    "    # Convert the headlines into a matrix of n-gram counts\n",
    "    headline_matrix = vectorizer.fit_transform(headlines)\n",
    "\n",
    "    # Create an SVM classifier\n",
    "    svm1 = svm.SVC(kernel='linear')\n",
    "\n",
    "    # Perform 10-fold cross-validation\n",
    "    scores = cross_val_score(svm1, headline_matrix, labels, cv=10)\n",
    "\n",
    "    # Print the accuracy for each fold\n",
    "    for fold, score in enumerate(scores):\n",
    "        print(f\"Fold {fold+1} Accuracy: {score}\")\n",
    "\n",
    "    # Train the SVM classifier on the entire dataset\n",
    "    svm1.fit(headline_matrix, labels)\n",
    "\n",
    "    # Save the vectorizer and classifier to files\n",
    "    with open('vectorizer1.pickle', 'wb') as handle:\n",
    "        pickle.dump(vectorizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    with open('classifier1.pickle', 'wb') as handle:\n",
    "        pickle.dump(svm1, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    return vectorizer, svm1\n",
    "\n",
    "# Call the function to train the SVM model and perform 10-fold cross-validation\n",
    "vectorizer, svm1 = train_svm1()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Classification (SVM 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Features Used\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "\n",
    "idiom_pattern = [{'LOWER': 'in'}, {'LOWER': 'the'}, {'LOWER': 'end'}, {'LOWER': 'of'}, {'LOWER': 'the'}, {'LOWER': 'day'}]\n",
    "matcher.add(\"idiom\", [idiom_pattern])\n",
    "\n",
    "def getSentimentFeature(sum_pos_score, sum_neg_score):\n",
    "\n",
    "    # compute sentiment score levels for positive sentiment\n",
    "    if sum_pos_score <= 1:\n",
    "        pos_level = \"low\"\n",
    "    elif sum_pos_score >= 2:\n",
    "        pos_level = \"high\"\n",
    "    else:\n",
    "        pos_level = \"medium\"\n",
    "\n",
    "    # compute sentiment score levels for negative sentiment\n",
    "    if sum_neg_score < -2:\n",
    "        neg_level = \"high\"\n",
    "    elif -2 <= sum_neg_score < -1:\n",
    "        neg_level = \"medium\"\n",
    "    else:\n",
    "        neg_level = \"low\"\n",
    "\n",
    "    return pos_level, neg_level\n",
    "\n",
    "def count_repetitive_punctuations(text):\n",
    "    pattern = r'(!{2,}|\\?{2,}|\\.+|,{2,})'\n",
    "    matches = re.findall(pattern, text)\n",
    "    return len(matches)\n",
    "\n",
    "def count_repetitive_characters(text):\n",
    "    pattern = r'(\\w{2,})\\1{1,}'\n",
    "    matches = re.findall(pattern, text)\n",
    "    return len(matches)\n",
    "\n",
    "def count_capitalized_words(text):\n",
    "    words = text.split()\n",
    "    capitalized_words = [w for w in words if w.isupper()]\n",
    "    return len(capitalized_words)\n",
    "\n",
    "\n",
    "def count_slang_booster_words(headline):\n",
    "    # Define a list of booster and slang words\n",
    "    booster_words = ['outstanding', 'exceptional', 'remarkable', 'superb', 'excellent', 'terrific', 'fabulous', 'splendid', 'majestic', 'breathtaking', 'wonderful', 'marvelous', 'extraordinary', 'amazing', 'awesome', 'incredible', 'fantastic', 'unbelievable', 'phenomenal', 'mind-blowing', 'epic', 'legendary', 'spectacular', 'jaw-dropping', 'astounding', 'awe-inspiring', 'stunning', 'gorgeous', 'beautiful', 'mesmerizing', 'captivating', 'charming', 'delightful', 'enchanting']\n",
    "    slang_words = ['lit', 'squad', 'bae', 'fomo', 'salty', 'cray', 'yolo', 'hundo', 'goat', 'savage', 'dope', 'fire', 'fleek', 'lit af', 'thicc', 'on fleek', 'gucci', 'shook', 'fam', 'hella', 'woke', 'turnt', 'baeless', 'basic', 'high-key', 'low-key', 'extra', 'thirsty', 'slay', 'swag', 'trap', 'clap back', 'thot', 'twerk', 'dank', 'sippin tea', 'chill', 'ghost', 'shade', 'throwing shade', 'baewatch', 'bye Felicia']\n",
    "\n",
    "    # Count the number of booster and slang words\n",
    "    booster_count = 0\n",
    "    slang_count = 0\n",
    "    words=headline.split()\n",
    "    for token in words:\n",
    "        if token.lower() in booster_words:\n",
    "            booster_count += 1\n",
    "        if token.lower() in slang_words:\n",
    "            slang_count += 1\n",
    "\n",
    "    return booster_count + slang_count\n",
    "\n",
    "\n",
    "def count_exclamation_marks(text):\n",
    "    exclamation_marks = [c for c in text if c == \"!\"]\n",
    "    return len(exclamation_marks)\n",
    "\n",
    "def count_idioms_in_headline(headline):\n",
    "    doc = nlp(headline)\n",
    "    matches = matcher(doc)\n",
    "    idiom_count = len(matches)\n",
    "    return idiom_count\n",
    "\n",
    "def make_features(data):\n",
    "    # Initialize empty feature dictionary\n",
    "    features_set={}\n",
    "    \n",
    "    features={}\n",
    "    #print(i)\n",
    "    headline = data        \n",
    "    features['headline'] = headline                \n",
    "    sum_pos_score,sum_neg_score,contra = sentiment(headline)\n",
    "    doc = nlp(headline)\n",
    "    # Check the number of sentences in the document\n",
    "    num_sentences = len(list(doc.sents))\n",
    "    \n",
    "    if num_sentences > 1:\n",
    "        coher=check_coherence(headline)\n",
    "        if coher==True and contra==True:\n",
    "            features['contra+coher'] = True\n",
    "            features['contra'] = True\n",
    "        elif contra==True:\n",
    "            features['contra+coher'] = False\n",
    "            features['contra'] = True\n",
    "        else:\n",
    "            features['contra+coher'] = False\n",
    "            features['contra'] = False\n",
    "    elif contra==True:\n",
    "        features['contra+coher'] = False\n",
    "        features['contra'] = True\n",
    "    else:\n",
    "        features['contra+coher'] = False\n",
    "        features['contra'] = False\n",
    "    features['sum_pos_score'] = sum_pos_score\n",
    "    features['sum_neg_score'] = sum_neg_score\n",
    "    c1=count_repetitive_punctuations(headline)\n",
    "    if c1==0:\n",
    "        l=True\n",
    "        m=False\n",
    "        h=False\n",
    "    elif c1 >= 1 and c1 <= 3:\n",
    "        l=False\n",
    "        m=True\n",
    "        h=False\n",
    "    else:\n",
    "        l=False\n",
    "        m=True\n",
    "        h=False\n",
    "    P1={'low':l,'med':m,'high':h}\n",
    "    features['P1_low'] = P1['low']\n",
    "    features['P1_med'] = P1['med']\n",
    "    features['P1_high'] = P1['high']\n",
    "    c2=count_repetitive_characters(headline)\n",
    "    if c2==0:\n",
    "        l2=True\n",
    "        m2=False\n",
    "        h2=False\n",
    "    elif c2 >= 1 and c2 <= 3:\n",
    "        l2=False\n",
    "        m2=True\n",
    "        h2=False\n",
    "    else:\n",
    "        l2=False\n",
    "        m2=True\n",
    "        h2=False\n",
    "    P2={'low':l2,'med':m2,'high':h2}\n",
    "    features['P2_low'] = P2['low']\n",
    "    features['P2_med'] = P2['med']\n",
    "    features['P2_high'] = P2['high']\n",
    "    c3=count_capitalized_words(headline)\n",
    "    if c3==0:\n",
    "        l3=True\n",
    "        m3=False\n",
    "        h3=False\n",
    "    elif c3 >= 1 and c3 <= 3:\n",
    "        l3=False\n",
    "        m3=True\n",
    "        h3=False\n",
    "    else:\n",
    "        l3=False\n",
    "        m3=True\n",
    "        h3=False\n",
    "    P3={'low':l3,'med':m3,'high':h3}\n",
    "    features['P3_low'] = P3['low']\n",
    "    features['P3_med'] = P3['med']\n",
    "    features['P3_high'] = P3['high']\n",
    "    c4=count_slang_booster_words(headline)\n",
    "    if c4==0:\n",
    "        l4=True\n",
    "        m4=False\n",
    "        h4=False\n",
    "    elif c4 >= 1 and c4 <= 3:\n",
    "        l4=False\n",
    "        m4=True\n",
    "        h4=False\n",
    "    else:\n",
    "        l4=False\n",
    "        m4=True\n",
    "        h4=False\n",
    "    P4={'low':l4,'med':m4,'high':h4}\n",
    "    features['P4_low'] = P4['low']\n",
    "    features['P4_med'] = P4['med']\n",
    "    features['P4_high'] = P4['high']\n",
    "    c5=count_exclamation_marks(headline)\n",
    "    if c5==0:\n",
    "        l5=True\n",
    "        m5=False\n",
    "        h5=False\n",
    "    elif c5 >= 1 and c5 <= 3:\n",
    "        l5=False\n",
    "        m5=True\n",
    "        h5=False\n",
    "    else:\n",
    "        l5=False\n",
    "        m5=True\n",
    "        h5=False\n",
    "    P5={'low':l5,'med':m5,'high':h5}\n",
    "    features['P5_low'] = P5['low']\n",
    "    features['P5_med'] = P5['med']\n",
    "    features['P5_high'] = P5['high']\n",
    "    c6=count_idioms_in_headline(headline)\n",
    "    if c6==0:\n",
    "        l6=True\n",
    "        m6=False\n",
    "        h6=False\n",
    "    elif c6 >= 1 and c6 <= 3:\n",
    "        l6=False\n",
    "        m6=True\n",
    "        h6=False\n",
    "    else:\n",
    "        l6=False\n",
    "        m6=True\n",
    "        h6=False\n",
    "    P6={'low':l6,'med':m6,'high':h6}\n",
    "    features['P6_low'] = P3['low']\n",
    "    features['P6_med'] = P3['med']\n",
    "    features['P6_high'] = P3['high']\n",
    "    pos_level,neg_level=getSentimentFeature(sum_pos_score,sum_neg_score)\n",
    "    if pos_level == \"high\":\n",
    "        features['P7_high'] = True\n",
    "        features['P7_med'] = False\n",
    "        features['P7_low'] = False\n",
    "    if pos_level == \"medium\":\n",
    "        features['P7_high'] = False\n",
    "        features['P7_med'] = True\n",
    "        features['P7_low'] = False\n",
    "    if pos_level == \"low\":\n",
    "        features['P7_high'] = False\n",
    "        features['P7_med'] = False\n",
    "        features['P7_low'] = True\n",
    "    if neg_level == \"high\":\n",
    "        features['P8_high'] = True\n",
    "        features['P8_med'] = False\n",
    "        features['P8_low'] = False\n",
    "    if neg_level == \"medium\":\n",
    "        features['P8_high'] = False\n",
    "        features['P8_med'] = True\n",
    "        features['P8_low'] = False\n",
    "    if neg_level == \"low\":\n",
    "        features['P8_high'] = False\n",
    "        features['P8_med'] = False\n",
    "        features['P8_low'] = True      \n",
    "\n",
    "    \n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.56535231372615\n"
     ]
    }
   ],
   "source": [
    "#Implementation of these features\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn import svm\n",
    "import re\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "def make_features_svm(data):\n",
    "    # Initialize empty feature dictionary\n",
    "    features_set={}\n",
    "    for i in range(len(data)):\n",
    "        features={}\n",
    "        print(i)\n",
    "        headline = data[str(i)]['headline']        \n",
    "        features['headline'] = headline                \n",
    "        sum_pos_score,sum_neg_score,contra = sentiment(headline)\n",
    "        doc = nlp(headline)\n",
    "        # Check the number of sentences in the document\n",
    "        num_sentences = len(list(doc.sents))\n",
    "        \n",
    "        if num_sentences > 1:\n",
    "            coher=check_coherence(headline)\n",
    "            if coher==True and contra==True:\n",
    "                features['contra+coher'] = True\n",
    "                features['contra'] = True\n",
    "            elif contra==True:\n",
    "                features['contra+coher'] = False\n",
    "                features['contra'] = True\n",
    "            else:\n",
    "                features['contra+coher'] = False\n",
    "                features['contra'] = False\n",
    "        elif contra==True:\n",
    "            features['contra+coher'] = False\n",
    "            features['contra'] = True\n",
    "        else:\n",
    "            features['contra+coher'] = False\n",
    "            features['contra'] = False\n",
    "        features['sum_pos_score'] = sum_pos_score\n",
    "        features['sum_neg_score'] = sum_neg_score\n",
    "        c1=count_repetitive_punctuations(headline)\n",
    "        if c1==0:\n",
    "            l=True\n",
    "            m=False\n",
    "            h=False\n",
    "        elif c1 >= 1 and c1 <= 3:\n",
    "            l=False\n",
    "            m=True\n",
    "            h=False\n",
    "        else:\n",
    "            l=False\n",
    "            m=True\n",
    "            h=False\n",
    "        P1={'low':l,'med':m,'high':h}\n",
    "        features['P1_low'] = P1['low']\n",
    "        features['P1_med'] = P1['med']\n",
    "        features['P1_high'] = P1['high']\n",
    "        c2=count_repetitive_characters(headline)\n",
    "        if c2==0:\n",
    "            l2=True\n",
    "            m2=False\n",
    "            h2=False\n",
    "        elif c2 >= 1 and c2 <= 3:\n",
    "            l2=False\n",
    "            m2=True\n",
    "            h2=False\n",
    "        else:\n",
    "            l2=False\n",
    "            m2=True\n",
    "            h2=False\n",
    "        P2={'low':l2,'med':m2,'high':h2}\n",
    "        features['P2_low'] = P2['low']\n",
    "        features['P2_med'] = P2['med']\n",
    "        features['P2_high'] = P2['high']\n",
    "        c3=count_capitalized_words(headline)\n",
    "        if c3==0:\n",
    "            l3=True\n",
    "            m3=False\n",
    "            h3=False\n",
    "        elif c3 >= 1 and c3 <= 3:\n",
    "            l3=False\n",
    "            m3=True\n",
    "            h3=False\n",
    "        else:\n",
    "            l3=False\n",
    "            m3=True\n",
    "            h3=False\n",
    "        P3={'low':l3,'med':m3,'high':h3}\n",
    "        features['P3_low'] = P3['low']\n",
    "        features['P3_med'] = P3['med']\n",
    "        features['P3_high'] = P3['high']\n",
    "        c4=count_slang_booster_words(headline)\n",
    "        if c4==0:\n",
    "            l4=True\n",
    "            m4=False\n",
    "            h4=False\n",
    "        elif c4 >= 1 and c4 <= 3:\n",
    "            l4=False\n",
    "            m4=True\n",
    "            h4=False\n",
    "        else:\n",
    "            l4=False\n",
    "            m4=True\n",
    "            h4=False\n",
    "        P4={'low':l4,'med':m4,'high':h4}\n",
    "        features['P4_low'] = P4['low']\n",
    "        features['P4_med'] = P4['med']\n",
    "        features['P4_high'] = P4['high']\n",
    "        c5=count_exclamation_marks(headline)\n",
    "        if c5==0:\n",
    "            l5=True\n",
    "            m5=False\n",
    "            h5=False\n",
    "        elif c5 >= 1 and c5 <= 3:\n",
    "            l5=False\n",
    "            m5=True\n",
    "            h5=False\n",
    "        else:\n",
    "            l5=False\n",
    "            m5=True\n",
    "            h5=False\n",
    "        P5={'low':l5,'med':m5,'high':h5}\n",
    "        features['P5_low'] = P5['low']\n",
    "        features['P5_med'] = P5['med']\n",
    "        features['P5_high'] = P5['high']\n",
    "        c6=count_idioms_in_headline(headline)\n",
    "        if c6==0:\n",
    "            l6=True\n",
    "            m6=False\n",
    "            h6=False\n",
    "        elif c6 >= 1 and c6 <= 3:\n",
    "            l6=False\n",
    "            m6=True\n",
    "            h6=False\n",
    "        else:\n",
    "            l6=False\n",
    "            m6=True\n",
    "            h6=False\n",
    "        P6={'low':l6,'med':m6,'high':h6}\n",
    "        features['P6_low'] = P3['low']\n",
    "        features['P6_med'] = P3['med']\n",
    "        features['P6_high'] = P3['high']\n",
    "        pos_level,neg_level=getSentimentFeature(sum_pos_score,sum_neg_score)\n",
    "        if pos_level == \"high\":\n",
    "            features['P7_high'] = True\n",
    "            features['P7_med'] = False\n",
    "            features['P7_low'] = False\n",
    "        if pos_level == \"medium\":\n",
    "            features['P7_high'] = False\n",
    "            features['P7_med'] = True\n",
    "            features['P7_low'] = False\n",
    "        if pos_level == \"low\":\n",
    "            features['P7_high'] = False\n",
    "            features['P7_med'] = False\n",
    "            features['P7_low'] = True\n",
    "        if neg_level == \"high\":\n",
    "            features['P8_high'] = True\n",
    "            features['P8_med'] = False\n",
    "            features['P8_low'] = False\n",
    "        if neg_level == \"medium\":\n",
    "            features['P8_high'] = False\n",
    "            features['P8_med'] = True\n",
    "            features['P8_low'] = False\n",
    "        if neg_level == \"low\":\n",
    "            features['P8_high'] = False\n",
    "            features['P8_med'] = False\n",
    "            features['P8_low'] = True      \n",
    "        features_set[i]=features\n",
    "        \n",
    "    return features_set\n",
    "\n",
    "# Function to extract features from a headline\n",
    "def extract_features(headline_dict, i):\n",
    "    # Initialize empty feature dictionary\n",
    "    features = {}\n",
    "    i=str(i)\n",
    "\n",
    "    # Extract the required features\n",
    "    features['sum_neg_score'] = headline_dict[i]['sum_neg_score']\n",
    "    features['sum_pos_score'] = headline_dict[i]['sum_pos_score']\n",
    "    features['contra'] = headline_dict[i]['contra']\n",
    "    features['contra+coher'] = headline_dict[i]['contra+coher']\n",
    "    features['P1_low']=headline_dict[i]['P1_low']\n",
    "    features['P1_med']=headline_dict[i]['P1_med']\n",
    "    features['P1_high']=headline_dict[i]['P1_high']\n",
    "\n",
    "    features['P2_low']=headline_dict[i]['P2_low']\n",
    "    features['P2_med']=headline_dict[i]['P2_med']\n",
    "    features['P2_high']=headline_dict[i]['P2_high']\n",
    "\n",
    "    features['P3_low']=headline_dict[i]['P3_low']\n",
    "    features['P3_med']=headline_dict[i]['P3_med']\n",
    "    features['P3_high']=headline_dict[i]['P3_high']\n",
    "\n",
    "    features['P4_low']=headline_dict[i]['P4_low']\n",
    "    features['P4_med']=headline_dict[i]['P4_med']\n",
    "    features['P4_high']=headline_dict[i]['P4_high']\n",
    "\n",
    "    features['P5_low']=headline_dict[i]['P5_low']\n",
    "    features['P5_med']=headline_dict[i]['P5_med']\n",
    "    features['P5_high']=headline_dict[i]['P5_high']\n",
    "\n",
    "    features['P6_low']=headline_dict[i]['P6_low']\n",
    "    features['P6_med']=headline_dict[i]['P6_med']\n",
    "    features['P6_high']=headline_dict[i]['P6_high']\n",
    "    \n",
    "    features['P7_low']=headline_dict[i]['P7_low']\n",
    "    features['P7_med']=headline_dict[i]['P7_med']\n",
    "    features['P7_high']=headline_dict[i]['P7_high']\n",
    "\n",
    "    features['P8_low']=headline_dict[i]['P8_low']\n",
    "    features['P8_med']=headline_dict[i]['P8_med']\n",
    "    features['P8_high']=headline_dict[i]['P8_high']\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "# Function to train SVM classifier using 10-fold cross-validation\n",
    "def train_svm2():\n",
    "    # Load the training data from the JSON file\n",
    "    with open(\"Lemma_Data.json\", 'r') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    with open(\"Features.json\", \"r\") as f:\n",
    "        new_features = json.load(f)\n",
    "\n",
    "    # Extract the headlines and labels from the JSON data\n",
    "    headlines = []\n",
    "    labels = []\n",
    "    feature_data = {}\n",
    "    for i in range(len(data)):\n",
    "        headline = data[str(i)]['headline']\n",
    "        label = data[str(i)]['is_sarcastic']\n",
    "        headlines.append(headline)\n",
    "        labels.append(label)\n",
    "\n",
    "    # Extract features from the headlines using the extract_features function\n",
    "    features = [extract_features(new_features, i) for i in range(len(new_features))]\n",
    "\n",
    "    # Create a DictVectorizer object to convert the feature dictionaries into matrices\n",
    "    vectorizer = DictVectorizer()\n",
    "\n",
    "    # Convert the feature dictionaries into a matrix of feature vectors\n",
    "    feature_matrix = vectorizer.fit_transform(features)\n",
    "\n",
    "    # Perform 10-fold cross-validation\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    accuracies = []\n",
    "\n",
    "    for train_index, test_index in kf.split(feature_matrix):\n",
    "        X_train, X_test = feature_matrix[train_index], feature_matrix[test_index]\n",
    "        y_train, y_test = np.array(labels)[train_index], np.array(labels)[test_index]\n",
    "\n",
    "        # Create an SVM classifier and fit it to the training data\n",
    "        clf = svm.SVC(kernel='linear')\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        # Evaluate the classifier on the testing data\n",
    "        accuracy = clf.score(X_test, y_test)\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "    # Calculate the average accuracy across all folds\n",
    "    avg_accuracy = np.mean(accuracies)\n",
    "    print(\"Average Accuracy:\", avg_accuracy)\n",
    "\n",
    "    # Save the vectorizer and classifier to files\n",
    "    with open('vectorizer2.pickle', 'wb') as handle:\n",
    "        pickle.dump(vectorizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    with open('classifier2.pickle', 'wb') as handle:\n",
    "        pickle.dump(clf, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    return vectorizer, clf\n",
    "\n",
    "# Example usage\n",
    "vectorizer2, svm2 = train_svm2()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge SVMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Load the saved classifiers\n",
    "with open('vectorizer1.pickle', 'rb') as handle:\n",
    "    vectorizer1 = pickle.load(handle)\n",
    "\n",
    "with open('classifier1.pickle', 'rb') as handle:\n",
    "    svm1 = pickle.load(handle)\n",
    "\n",
    "with open('vectorizer2.pickle', 'rb') as handle:\n",
    "    vectorizer2 = pickle.load(handle)\n",
    "\n",
    "with open('classifier2.pickle', 'rb') as handle:\n",
    "    svm2 = pickle.load(handle)\n",
    "\n",
    "# Load the test data\n",
    "with open(\"Lemma_Data.json\", 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Extract the headlines and labels from the test data\n",
    "test_headlines = []\n",
    "test_labels = []\n",
    "for i in range(len(data)):\n",
    "    headline = data[str(i)]['headline']\n",
    "    label = data[str(i)]['is_sarcastic']\n",
    "    test_headlines.append(headline)\n",
    "    test_labels.append(label)\n",
    "\n",
    "with open(\"Features.json\", \"r\") as f:\n",
    "    new_features = json.load(f)\n",
    "\n",
    "features = [extract_features(new_features, i) for i in range(len(new_features))]\n",
    "test_matrix1 = vectorizer1.transform(test_headlines)\n",
    "test_matrix2 = vectorizer2.transform(features)\n",
    "\n",
    "# Predict the labels for the test data using both SVM classifiers\n",
    "predicted_labels1 = svm1.predict(test_matrix1)\n",
    "predicted_labels2 = svm2.predict(test_matrix2)\n",
    "\n",
    "# Perform majority voting to merge the predictions\n",
    "merged_predictions = []\n",
    "for label1, label2 in zip(predicted_labels1, predicted_labels2):\n",
    "    if label1 == label2:\n",
    "        merged_predictions.append(label1)\n",
    "    else:\n",
    "        merged_predictions.append(0)  # Assign a default label when there's no majority\n",
    "\n",
    "# Apply 10-fold cross-validation to the merged predictions\n",
    "scores = cross_val_score(svm1, test_matrix1, test_labels, cv=10)\n",
    "average_accuracy = scores.mean()\n",
    "print(\"Merged SVM Accuracy (10-fold CV):\", average_accuracy)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Headline is not sarcastic\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "#nltk.download('wordnet')\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_text = []\n",
    "\n",
    "    # Tokenize the text into words\n",
    "    words = nltk.word_tokenize(text)\n",
    "\n",
    "    # Lemmatize each word\n",
    "    for word in words:\n",
    "        lemmatized_word = lemmatizer.lemmatize(word)\n",
    "        lemmatized_text.append(lemmatized_word)\n",
    "\n",
    "    # Join the lemmatized words back into a single string\n",
    "    lemmatized_text = ' '.join(lemmatized_text)\n",
    "\n",
    "    return lemmatized_text\n",
    "headline= \"Trump is the new jesus!!!!\"\n",
    "\n",
    "\n",
    "headline=lemmatize_text(headline)\n",
    "\n",
    "\n",
    "with open('vectorizer2.pickle', 'rb') as handle:\n",
    "   vectorizer2 = pickle.load(handle)\n",
    "\n",
    "\n",
    "with open('classifier2.pickle', 'rb') as handle:\n",
    "   svm2 = pickle.load(handle)\n",
    "\n",
    "# Load the vectorizer from file\n",
    "with open('vectorizer1.pickle', 'rb') as handle:\n",
    "    vectorizer1 = pickle.load(handle)\n",
    "\n",
    "# Load the classifier from file\n",
    "with open('classifier1.pickle', 'rb') as handle:\n",
    "    svm1 = pickle.load(handle)\n",
    "# Predict the label for a new headline\n",
    "new_matrix = vectorizer1.transform([headline])\n",
    "\n",
    "features=make_features(headline)\n",
    "new_matrix_svm2=vectorizer2.transform(features)\n",
    "class1 = svm1.predict(new_matrix)[0]\n",
    "class2 = svm2.predict(new_matrix_svm2)[0]\n",
    "\n",
    "if class1 == class2:\n",
    "    # The classifiers agree, so we use the majority vote\n",
    "    final_result = class1\n",
    "else:\n",
    "    # The classifiers disagree, so we need to compare the margins\n",
    "    margin1 = svm1.decision_function(new_matrix)\n",
    "    margin2 = svm2.decision_function(new_matrix_svm2)\n",
    "    \n",
    "    if margin1 > margin2:\n",
    "        final_result = class1\n",
    "    else:\n",
    "        final_result = class2\n",
    "\n",
    "#print(final_result)\n",
    "\n",
    "if final_result == 1:\n",
    "    print('Headline is sarcastic')\n",
    "else:\n",
    "    print('Headline is not sarcastic')   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
